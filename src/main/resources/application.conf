akka {

  # Akka logging configuration. ***Do not touch. To configure logging, see logback.xml.***

  # If you set the loglevel to a higher level than "DEBUG", any DEBUG events will be filtered out already
  # at the source and will never reach the logging backend, regardless of how logging is configured there.
  loglevel = DEBUG
  # Optimization: If an event would not be logged by slf4j, it will not be sent to the logging event bus.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  # Only use the slf4j logging, do not log directly to console.
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  stdout-loglevel = OFF
  logger-startup-timeout = 60s

  log-dead-letters = 100
  log-dead-letters-during-shutdown = false

  actor {
    #provider = akka.cluster.ClusterActorRefProvider
    provider = cluster
  }

  remote = {
    #enabled-transports = ["akka.remote.netty.tcp"]

    artery {
      enabled = true
      transport = tcp
    }
  }

  cluster {
    configuration-compatibility-check.enforce-on-join = off

    # General recomentation how to pick AutoDowning provides is following:
    # If you have a static cluster (like always 3 or 5 nodes) - use Static Quorum (QuorumLeaderAutoDowning)
    # If you have a mode flexible scenarion where you scale up for 5 tp 9 and down to 7 - use Keep Majority (MajorityLeaderAutoDowning)

    #https://github.com/TanUkkii007/akka-cluster-custom-downing#akka-cluster-custom-downing

    # MajorityLeaderAutoDowning is similar to  QuorumLeaderAutoDowning. However, instead of a static specified quorum size
    # this strategy automatically keeps the partition with the largest amount of nodes. If the partitions are of equal size,
    # the partition that contains the node with the globally lowest address is kept. The strategy is the same as the keep majority
    # strategy of Split Brain Resolver from Typesafe reactive platform. If a role is set by majority-member-role,
    # the strategy is only enforced to the nodes with the specified role.
    downing-provider-class = "tanukki.akka.cluster.autodown.MajorityLeaderAutoDowning"

    custom-downing {

      # Time margin after which shards or singletons that belonged to a downed/removed
      # partition are created in surviving partition. The purpose of this margin is that
      # in case of a network partition the persistent actors in the non-surviving partitions
      # must be stopped before corresponding persistent actors are started somewhere else.
      # This is useful if you implement downing strategies that handle network partitions,
      # e.g. by keeping the larger side of the partition and shutting down the smaller side.
      # Decision is taken by the strategy when there has been no membership or
      # reachability changes for this duration, i.e. the cluster state is stable.
      stable-after = 5s

      majority-leader-auto-downing {
        majority-member-role = ""
        down-if-in-minority = true
        shutdown-actor-system-on-resolution = true
      }
    }

    use-dispatcher = "akka.cluster-dispatcher"

    failure-detector {
      implementation-class = "akka.remote.PhiAccrualFailureDetector"
      threshold = 10.0
      heartbeat-interval = 1 s
      min-std-deviation = 100 ms
      acceptable-heartbeat-pause = 3 s
    }
    auto-down-unreachable-after = 5 seconds
  }

  metrics-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 2
    }
  }

  cluster-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 2
    }
  }


  shard-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 4
    }
  }

}

akka.cluster.metrics.enabled = off
akka.extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]

