akka {

  # Akka logging configuration. ***Do not touch. To configure logging, see logback.xml.***

  # If you set the loglevel to a higher level than "DEBUG", any DEBUG events will be filtered out already
  # at the source and will never reach the logging backend, regardless of how logging is configured there.
  loglevel = DEBUG
  # Optimization: If an event would not be logged by slf4j, it will not be sent to the logging event bus.
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  # Only use the slf4j logging, do not log directly to console.
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  stdout-loglevel = OFF
  logger-startup-timeout = 60s

  log-dead-letters = 100
  log-dead-letters-during-shutdown = false

  actor {
    #provider = akka.cluster.ClusterActorRefProvider
    provider = cluster
    warn-about-java-serializer-usage = off
  }

  remote = {
    #enabled-transports = ["akka.remote.netty.tcp"]

    artery {
      enabled = true
      transport = tcp

      advanced {

        //default 262 144 byte
        //now     26  214 400 byte
        maximum-frame-size = 25MiB

        #The default size of the system messages buffer is 20000
        #system-message-buffer-size = 20000

        # queue for outgoing control (system) messages
        #outbound-control-queue-size = 3072
      }

    }
  }

  cluster {
    configuration-compatibility-check.enforce-on-join = off

    # General recomentation how to pick AutoDowning provides is following:
    # If you have a static cluster (like always 3 or 5 nodes) - use Static Quorum (QuorumLeaderAutoDowning)
    # If you have a mode flexible scenarion where you scale up for 5 tp 9 and down to 7 - use Keep Majority (MajorityLeaderAutoDowning)

    #https://github.com/TanUkkii007/akka-cluster-custom-downing#akka-cluster-custom-downing

    # MajorityLeaderAutoDowning is similar to  QuorumLeaderAutoDowning. However, instead of a static specified quorum size
    # this strategy automatically keeps the partition with the largest amount of nodes. If the partitions are of equal size,
    # the partition that contains the node with the globally lowest address is kept. The strategy is the same as the keep majority
    # strategy of Split Brain Resolver from Typesafe reactive platform. If a role is set by majority-member-role,
    # the strategy is only enforced to the nodes with the specified role.
    downing-provider-class = "tanukki.akka.cluster.autodown.MajorityLeaderAutoDowning"

    custom-downing {

      # Time margin after which shards or singletons that belonged to a downed/removed
      # partition are created in surviving partition. The purpose of this margin is that
      # in case of a network partition the persistent actors in the non-surviving partitions
      # must be stopped before corresponding persistent actors are started somewhere else.
      # This is useful if you implement downing strategies that handle network partitions,
      # e.g. by keeping the larger side of the partition and shutting down the smaller side.
      # Decision is taken by the strategy when there has been no membership or
      # reachability changes for this duration, i.e. the cluster state is stable.
      stable-after = 5s

      majority-leader-auto-downing {
        majority-member-role = ""
        down-if-in-minority = true
        shutdown-actor-system-on-resolution = true
      }
    }

    use-dispatcher = "akka.cluster-dispatcher"

    failure-detector {
      implementation-class = "akka.remote.PhiAccrualFailureDetector"
      threshold = 10.0
      heartbeat-interval = 1 s
      min-std-deviation = 100 ms
      acceptable-heartbeat-pause = 3 s
    }

    #auto-down-unreachable-after = 5 seconds

    # CoordinatedShutdown will run the tasks that are added to these
    # phases. The phases can be ordered as a DAG by defining the
    # dependencies between the phases.
    # Each phase is defined as a named config section with the
    # following optional properties:
    # - timeout=15s: Override the default-phase-timeout for this phase.
    # - recover=off: If the phase fails the shutdown is aborted
    #                and depending phases will not be executed.
    # depends-on=[]: Run the phase after the given phases
    coordinated-shutdown {
      # Exit the JVM (System.exit(0)) in the last phase actor-system-terminate
      # if this is set to 'on'. It is done after termination of the
      # ActorSystem if terminate-actor-system=on, otherwise it is done
      # immediately when the last phase is reached.
      exit-jvm = on
      default-phase-timeout = 10 seconds
    }

    
    sharding {
      distributed-data.delta-crdt.enabled = off
      state-store-mode = ddata
    }

    persistence {
      use-dispatcher = shard-dispatcher
    }
  }

  #https://github.com/akka/akka-management/blob/master/cluster-http/src/main/resources/reference.conf
  management {
    # registers bootstrap routes to be included in akka-management's http endpoint
    # http.route-providers += "akka.management.cluster.ClusterHttpManagementRouteProvider"
    cluster.http {
      #host = 0.0.0.0
      #port = 19999
    }
  }

  metrics-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 2
    }
  }

  cluster-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 2
    }
  }


  shard-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 4
    }
  }

}

akka.cluster.metrics.enabled = off
akka.extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]

